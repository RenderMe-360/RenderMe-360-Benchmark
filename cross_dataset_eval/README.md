# Cross Dataset Evaluation

This track refers to the same setting of Generalizable NVS but training or testing on different multi-head datasets, to validate the transferability of our dataset.


## Train & Test data processing of Multiface
To align the scale of RenderMe-360 and Multiface dataset, we preprocess the image data of Multiface, and running the background matting.

Steps:
1. Download the Multiface dataset according to the official repo [Multiface](https://github.com/facebookresearch/multiface).
2. run the background matting. The matting method is the same as our pipeline.
3. Process the raw data (rescale and do the color correction).
```sh
$ sh process.sh
```

## Train & Test data processing of Facescape
To align the scale of RenderMe-360 and Facescape dataset, we preprocess the image data of Facescape, and running the background matting.

Steps:
1. Download the Facescape dataset according to the official repo [Facescape](https://facescape.nju.edu.cn/Page_Download/).
   1. Multi-view Data, as raw data.
   2. TU-Model, for matting calculation.
2. Process the raw data (rescale, background matting).
   1. Since Facescape provides TU-Model, the background matting result can be generated by Zbuffer.
```sh
$ sh process.sh
```

## Reimplementation of KeypointNeRF

### Preparation

1. Clone the official repo and build up the environment.
```sh
$ git clone https://github.com/facebookresearch/KeypointNeRF
```
2. Build up the python environment according to the official repo.
3. Replace the following files with the same place. 
```sh
$ mv cross_dataset_eval/keypointnerf/src/* keypointnerf/src/
$ mv cross_dataset_eval/keypointnerf/configs/* keypointnerf/configs/
$ mv cross_dataset_eval/keypointnerf/configs/* keypointnerf/configs/
$ mv cross_dataset_eval/keypointnerf/runs keypointnerf/
$ mv cross_dataset_eval/keypointnerf/calculate_metric.py keypointnerf/
$ mv cross_dataset_eval/keypointnerf/render_facescape.py keypointnerf/
$ mv cross_dataset_eval/keypointnerf/render_multiface.py keypointnerf/
$ mv cross_dataset_eval/keypointnerf/train.py keypointnerf/
```
4. We also provided our pre-trained checkpoints of keypointnerf [here](https://drive.google.com/drive/folders/16I1YUafmA36eHUJg2bBiCknxCyoDCRMV?usp=sharing).

### Multiface

1. Training
```sh
$ bash runs/train_mf.sh
```

2. Testing
```sh
$ bash runs/test_mf.sh
```

3. metric calculation
```sh
$ python calculate_metric.py [path to result folder]
```

### Facescape

1. Training
```sh
$ bash runs/train_fs.sh
```

2. Testing
```sh
$ bash runs/test_fs.sh
```

3. metric calculation
```sh
$ python calculate_metric.py [path to result folder]
```

## Citation

```
@inproceedings{wang2021ibrnet,
  year={2021},
  title={Ibrnet: Learning multi-view image-based rendering},
  author={Wang, Qianqian and Wang, Zhicheng and Genova, Kyle and Srinivasan, Pratul P and Zhou, Howard and Barron, Jonathan T and Martin-Brualla, Ricardo and Snavely, Noah and Funkhouser, Thomas},
  booktitle={CVPR}
}
```
```
@inproceedings{mihajlovic2022keypointnerf,
  year={2022},
  title={KeypointNeRF: Generalizing image-based volumetric avatars using relative spatial encoding of keypoints},
  author={Mihajlovic, Marko and Bansal, Aayush and Zollhoefer, Michael and Tang, Siyu and Saito, Shunsuke},
  booktitle={ECCV}
}
```
```
@inproceedings {lin2023visionnerf,
  year={2023},
    booktitle = {WACV},
    title = {Vision Transformer for NeRF-Based View Synthesis from a Single Input Image},
    author = {Lin, Kai-En and Yen-Chen, Lin and Lai, Wei-Sheng and Lin, Tsung-Yi and Shih, Yi-Chang and Ramamoorthi, Ravi},
}
```
```
@article{wuu2022multiface,
  year={2022},
  title={Multiface: A Dataset for Neural Face Rendering},
  author={Wuu, Cheng-hsin and Zheng, Ningyuan and Ardisson, Scott and Bali, Rohan and Belko, Danielle and Brockmeyer, Eric and Evans, Lucas and Godisart, Timothy and Ha, Hyowon and Hypes, Alexander and others},
  journal={arXiv}
}
```
```
@inproceedings{yang2020facescape,
  year={2020},
  title={Facescape: a large-scale high quality 3d face dataset and detailed riggable 3d face prediction},
  author={Yang, Haotian and Zhu, Hao and Wang, Yanru and Huang, Mingkai and Shen, Qiu and Yang, Ruigang and Cao, Xun},
  booktitle={CVPR}
}
```